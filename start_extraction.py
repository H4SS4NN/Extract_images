#!/usr/bin/env python3
"""
Script de d√©marrage rapide pour l'extraction PDF ULTRA SENSIBLE
G√®re automatiquement la configuration LLaVA et lance l'extraction
"""

import subprocess
import sys
import os
import time

def check_dependencies():
    """V√©rifie les d√©pendances"""
    print("üîç V√©rification des d√©pendances...")
    
    # V√©rifier Python
    if sys.version_info < (3, 7):
        print("‚ùå Python 3.7+ requis")
        return False
    
    # V√©rifier les modules
    try:
        import cv2
        import numpy as np
        import requests
        print("‚úÖ Modules Python OK")
    except ImportError as e:
        print(f"‚ùå Module manquant: {e}")
        print("üí° Installez avec: pip install opencv-python numpy requests")
        return False
    
    return True

def check_ollama():
    """V√©rifie Ollama"""
    print("üîç V√©rification d'Ollama...")
    
    try:
        import requests
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        if response.status_code == 200:
            models = response.json().get('models', [])
            llava_models = [m['name'] for m in models if 'llava' in m['name'].lower()]
            
            if llava_models:
                print(f"‚úÖ Ollama + LLaVA disponible: {llava_models[0]}")
                return True
            else:
                print("‚ö†Ô∏è Ollama disponible mais LLaVA non install√©")
                print("üí° Installez LLaVA avec: ollama pull llava")
                return False
        else:
            print("‚ùå Ollama non accessible")
            return False
    except:
        print("‚ùå Ollama non install√© ou non d√©marr√©")
        print("üí° Installez Ollama: https://ollama.ai/")
        return False

def start_ollama():
    """D√©marre Ollama si possible"""
    print("üöÄ Tentative de d√©marrage d'Ollama...")
    
    try:
        # Essayer de d√©marrer Ollama en arri√®re-plan
        subprocess.Popen(["ollama", "serve"], 
                        stdout=subprocess.DEVNULL, 
                        stderr=subprocess.DEVNULL)
        time.sleep(3)  # Attendre que Ollama d√©marre
        
        # V√©rifier si √ßa marche
        if check_ollama():
            print("‚úÖ Ollama d√©marr√© avec succ√®s")
            return True
        else:
            print("‚ö†Ô∏è Ollama n'a pas d√©marr√© automatiquement")
            return False
    except:
        print("‚ö†Ô∏è Impossible de d√©marrer Ollama automatiquement")
        print("üí° D√©marrez manuellement avec: ollama serve")
        return False

def run_extraction():
    """Lance l'extraction PDF"""
    print("\nüöÄ LANCEMENT DE L'EXTRACTION PDF ULTRA SENSIBLE")
    print("=" * 60)
    
    try:
        # Importer et lancer le script principal
        from extract_pdf_ultra_sensible import main
        main()
    except Exception as e:
        print(f"‚ùå Erreur lors du lancement: {e}")
        return False
    
    return True

def main():
    print("üéØ EXTRACTEUR PDF ULTRA SENSIBLE - D√âMARRAGE RAPIDE")
    print("=" * 60)
    
    # V√©rifier les d√©pendances
    if not check_dependencies():
        print("\n‚ùå D√©pendances manquantes - installation requise")
        return
    
    # V√©rifier Ollama
    ollama_ok = check_ollama()
    if not ollama_ok:
        print("\n‚ö†Ô∏è Ollama/LLaVA non disponible")
        print("üí° Le script fonctionnera sans LLaVA (correction automatique uniquement)")
        
        # Essayer de d√©marrer Ollama
        if not start_ollama():
            print("‚ö†Ô∏è Continuation sans LLaVA...")
    
    # Lancer l'extraction
    print("\n" + "="*60)
    if run_extraction():
        print("\n‚úÖ Extraction termin√©e avec succ√®s !")
    else:
        print("\n‚ùå Erreur lors de l'extraction")

if __name__ == "__main__":
    main()
