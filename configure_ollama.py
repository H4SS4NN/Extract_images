#!/usr/bin/env python3
"""
Script de configuration Ollama pour optimiser LLaVA
"""

import requests
import json
import time

def check_ollama_status():
    """V√©rifie le statut d'Ollama"""
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        if response.status_code == 200:
            models = response.json().get('models', [])
            print(f"‚úÖ Ollama est en cours d'ex√©cution")
            print(f"üì¶ Mod√®les disponibles: {[model['name'] for model in models]}")
            return True
        else:
            print(f"‚ùå Ollama r√©pond avec erreur: {response.status_code}")
            return False
    except Exception as e:
        print(f"‚ùå Ollama n'est pas accessible: {e}")
        print("üí° D√©marrez Ollama avec: ollama serve")
        return False

def optimize_llava():
    """Optimise LLaVA pour de meilleures performances"""
    try:
        # Configuration optimis√©e pour LLaVA
        config = {
            "model": "llava:latest",
            "options": {
                "temperature": 0.1,
                "top_p": 0.9,
                "max_tokens": 200,
                "num_ctx": 2048,
                "num_predict": 100,
                "num_gpu": 1,  # Utiliser GPU si disponible
                "num_thread": 4,  # Nombre de threads
                "repeat_penalty": 1.1,
                "stop": ["\n\n", "Human:", "Assistant:"]
            }
        }
        
        print("üîß Configuration de LLaVA pour de meilleures performances...")
        
        # Tester avec une requ√™te simple
        test_payload = {
            "model": "llava:latest",
            "prompt": "Test de performance",
            "stream": False,
            "options": config["options"]
        }
        
        print("‚è≥ Test de performance LLaVA...")
        start_time = time.time()
        
        response = requests.post("http://localhost:11434/api/generate", json=test_payload, timeout=60)
        
        if response.status_code == 200:
            end_time = time.time()
            duration = end_time - start_time
            print(f"‚úÖ LLaVA r√©pond en {duration:.1f} secondes")
            
            if duration < 10:
                print("üöÄ LLaVA est rapide - pr√™t pour l'analyse")
                return True
            elif duration < 30:
                print("‚ö†Ô∏è LLaVA est lent mais utilisable")
                return True
            else:
                print("üêå LLaVA est tr√®s lent - consid√©rez un mod√®le plus rapide")
                return False
        else:
            print(f"‚ùå Erreur test LLaVA: {response.status_code}")
            return False
            
    except requests.exceptions.Timeout:
        print("‚è∞ Timeout LLaVA - le mod√®le est trop lent")
        return False
    except Exception as e:
        print(f"‚ùå Erreur configuration LLaVA: {e}")
        return False

def suggest_alternatives():
    """Sugg√®re des alternatives si LLaVA est trop lent"""
    print("\nüí° ALTERNATIVES SI LLAVA EST TROP LENT:")
    print("=" * 50)
    print("1. Mod√®les plus rapides:")
    print("   - ollama pull llava:7b (plus petit)")
    print("   - ollama pull llava:13b (√©quilibr√©)")
    print("   - ollama pull llava:34b (plus pr√©cis mais plus lent)")
    print()
    print("2. Configuration syst√®me:")
    print("   - Augmentez la RAM allou√©e √† Ollama")
    print("   - Utilisez un GPU si disponible")
    print("   - Fermez les autres applications")
    print()
    print("3. Le script fonctionnera sans LLaVA:")
    print("   - Correction automatique des patterns")
    print("   - D√©tection OCR avec Tesseract")
    print("   - Analyse de coh√©rence basique")

def main():
    print("üîß CONFIGURATION OLLAMA POUR LLAVA")
    print("=" * 50)
    
    # V√©rifier Ollama
    if not check_ollama_status():
        return
    
    # Optimiser LLaVA
    if optimize_llava():
        print("\n‚úÖ LLaVA est configur√© et pr√™t !")
        print("üéØ Le script extract_pdf_ultra_sensible.py peut maintenant utiliser LLaVA")
    else:
        print("\n‚ö†Ô∏è LLaVA a des probl√®mes de performance")
        suggest_alternatives()
    
    print("\nüìã R√âSUM√â:")
    print("- LLaVA sera utilis√© pour l'analyse visuelle avanc√©e")
    print("- Si LLaVA est trop lent, le script utilisera la correction automatique")
    print("- Toutes les fonctionnalit√©s principales fonctionnent sans LLaVA")

if __name__ == "__main__":
    main()
